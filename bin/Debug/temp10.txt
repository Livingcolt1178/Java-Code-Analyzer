


package org.tensorflow.contrib.android
;


import android.content.res.AssetManager
;

import android.os.Build.VERSION
;

import android.os.Trace
;

import android.text.TextUtils
;

import android.util.Log
;

import java.io.ByteArrayOutputStream
;

import java.io.FileInputStream
;

import java.io.IOException
;

import java.io.InputStream
;

import java.nio.ByteBuffer
;

import java.nio.DoubleBuffer
;

import java.nio.FloatBuffer
;

import java.nio.IntBuffer
;

import java.nio.LongBuffer
;

import java.util.ArrayList
;

import java.util.List
;

import org.tensorflow.Graph
;

import org.tensorflow.Operation
;

import org.tensorflow.Session
;

import org.tensorflow.Tensor
;

import org.tensorflow.TensorFlow
;

import org.tensorflow.Tensors
;

import org.tensorflow.types.UInt8
;




public class TensorFlowInferenceInterface {
  private static final String TAG = "TensorFlowInferenceInterface"
;

  private static final String ASSET_FILE_PREFIX = "file:
;


  

  public TensorFlowInferenceInterface(AssetManager assetManager
,
 String model) {
    prepareNativeRuntime()
;


    this.modelName = model
;

    this.g = new Graph()
;

    this.sess = new Session(g)
;

    this.runner = sess.runner()
;


    final boolean hasAssetPrefix = model.startsWith(ASSET_FILE_PREFIX)
;

    InputStream is = null
;

    try {
      String aname = hasAssetPrefix ? model.split(ASSET_FILE_PREFIX)[1] : model
;

      is = assetManager.open(aname)
;

    } catch (IOException e) {
      if (hasAssetPrefix) {
        throw new RuntimeException("Failed to load model from '" + model + "'"
,
 e)
;

      }
      
      try {
        is = new FileInputStream(model)
;

      } catch (IOException e2) {
        throw new RuntimeException("Failed to load model from '" + model + "'"
,
 e)
;

      }
    }

    try {
      if (VERSION.SDK_INT >= 18) {
        Trace.beginSection("initializeTensorFlow")
;

        Trace.beginSection("readGraphDef")
;

      }

      
      byte[] graphDef = new byte[is.available()]
;

      final int numBytesRead = is.read(graphDef)
;

      if (numBytesRead != graphDef.length) {
        throw new IOException(
            "read error: read only "
                + numBytesRead
                + " of the graph
,
 expected to read "
                + graphDef.length)
;

      }

      if (VERSION.SDK_INT >= 18) {
        Trace.endSection()
;
 
      }

      loadGraph(graphDef
,
 g)
;

      is.close()
;

      Log.i(TAG
,
 "Successfully loaded model from '" + model + "'")
;


      if (VERSION.SDK_INT >= 18) {
        Trace.endSection()
;
 
      }
    } catch (IOException e) {
      throw new RuntimeException("Failed to load model from '" + model + "'"
,
 e)
;

    }
  }

  

  public TensorFlowInferenceInterface(InputStream is) {
    prepareNativeRuntime()
;


    
,
 here is for
    
    this.modelName = ""
;

    this.g = new Graph()
;

    this.sess = new Session(g)
;

    this.runner = sess.runner()
;


    try {
      if (VERSION.SDK_INT >= 18) {
        Trace.beginSection("initializeTensorFlow")
;

        Trace.beginSection("readGraphDef")
;

      }

      int baosInitSize = is.available() > 16384 ? is.available() : 16384
;

      ByteArrayOutputStream baos = new ByteArrayOutputStream(baosInitSize)
;

      int numBytesRead
;

      byte[] buf = new byte[16384]
;

      while ((numBytesRead = is.read(buf
,
 0
,
 buf.length)) != -1) {
        baos.write(buf
,
 0
,
 numBytesRead)
;

      }
      byte[] graphDef = baos.toByteArray()
;


      if (VERSION.SDK_INT >= 18) {
        Trace.endSection()
;
 
      }

      loadGraph(graphDef
,
 g)
;

      Log.i(TAG
,
 "Successfully loaded model from the input stream")
;


      if (VERSION.SDK_INT >= 18) {
        Trace.endSection()
;
 
      }
    } catch (IOException e) {
      throw new RuntimeException("Failed to load model from the input stream"
,
 e)
;

    }
  }

  

  public TensorFlowInferenceInterface(Graph g) {
    prepareNativeRuntime()
;


    
,
 here is for
    
    this.modelName = ""
;

    this.g = g
;

    this.sess = new Session(g)
;

    this.runner = sess.runner()
;

  }

  

  public void run(String[] outputNames) {
    run(outputNames
,
 false)
;

  }

  

  public void run(String[] outputNames
,
 boolean enableStats) {
    run(outputNames
,
 enableStats
,
 new String[] {})
;

  }

  
  public void run(String[] outputNames
,
 boolean enableStats
,
 String[] targetNodeNames) {
    
    closeFetches()
;


    
    for (String o : outputNames) {
      fetchNames.add(o)
;

      TensorId tid = TensorId.parse(o)
;

      runner.fetch(tid.name
,
 tid.outputIndex)
;

    }

    
    for (String t : targetNodeNames) {
      runner.addTarget(t)
;

    }

    
    try {
      if (enableStats) {
        Session.Run r = runner.setOptions(RunStats.runOptions()).runAndFetchMetadata()
;

        fetchTensors = r.outputs
;


        if (runStats == null) {
          runStats = new RunStats()
;

        }
        runStats.add(r.metadata)
;

      } else {
        fetchTensors = runner.run()
;

      }
    } catch (RuntimeException e) {
      
,
 but since this interface predates the
      
,
 must return -1.
      Log.e(
          TAG
,

          "Failed to run TensorFlow inference with inputs:["
              + TextUtils.join("
,
 "
,
 feedNames)
              + "]
,
 outputs:["
              + TextUtils.join("
,
 "
,
 fetchNames)
              + "]")
;

      throw e
;

    } finally {
      
,
 this run is
      
      closeFeeds()
;

      runner = sess.runner()
;

    }
  }

  
  public Graph graph() {
    return g
;

  }

  public Operation graphOperation(String operationName) {
    final Operation operation = g.operation(operationName)
;

    if (operation == null) {
      throw new RuntimeException(
          "Node '" + operationName + "' does not exist in model '" + modelName + "'")
;

    }
    return operation
;

  }

  
  public String getStatString() {
    return (runStats == null) ? "" : runStats.summary()
;

  }

  

  public void close() {
    closeFeeds()
;

    closeFetches()
;

    sess.close()
;

    g.close()
;

    if (runStats != null) {
      runStats.close()
;

    }
    runStats = null
;

  }

  @Override
  protected void finalize() throws Throwable {
    try {
      close()
;

    } finally {
      super.finalize()
;

    }
  }

  

  

  public void feed(String inputName
,
 boolean[] src
,
 long... dims) {
    byte[] b = new byte[src.length]
;


    for (int i = 0
;
 i < src.length
;
 i++) {
      b[i] = src[i] ? (byte) 1 : (byte) 0
;

    }

    addFeed(inputName
,
 Tensor.create(Boolean.class
,
 dims
,
 ByteBuffer.wrap(b)))
;

  }

  

  public void feed(String inputName
,
 float[] src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 FloatBuffer.wrap(src)))
;

  }

  

  public void feed(String inputName
,
 int[] src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 IntBuffer.wrap(src)))
;

  }

  

  public void feed(String inputName
,
 long[] src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 LongBuffer.wrap(src)))
;

  }

  

  public void feed(String inputName
,
 double[] src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 DoubleBuffer.wrap(src)))
;

  }

  

  public void feed(String inputName
,
 byte[] src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(UInt8.class
,
 dims
,
 ByteBuffer.wrap(src)))
;

  }

  

  public void feedString(String inputName
,
 byte[] src) {
    addFeed(inputName
,
 Tensors.create(src))
;

  }

  

  public void feedString(String inputName
,
 byte[][] src) {
    addFeed(inputName
,
 Tensors.create(src))
;

  }

  

  

  public void feed(String inputName
,
 FloatBuffer src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 src))
;

  }

  

  public void feed(String inputName
,
 IntBuffer src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 src))
;

  }

  

  public void feed(String inputName
,
 LongBuffer src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 src))
;

  }

  

  public void feed(String inputName
,
 DoubleBuffer src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(dims
,
 src))
;

  }

  

  public void feed(String inputName
,
 ByteBuffer src
,
 long... dims) {
    addFeed(inputName
,
 Tensor.create(UInt8.class
,
 dims
,
 src))
;

  }

  

  public void fetch(String outputName
,
 float[] dst) {
    fetch(outputName
,
 FloatBuffer.wrap(dst))
;

  }

  

  public void fetch(String outputName
,
 int[] dst) {
    fetch(outputName
,
 IntBuffer.wrap(dst))
;

  }

  

  public void fetch(String outputName
,
 long[] dst) {
    fetch(outputName
,
 LongBuffer.wrap(dst))
;

  }

  

  public void fetch(String outputName
,
 double[] dst) {
    fetch(outputName
,
 DoubleBuffer.wrap(dst))
;

  }

  

  public void fetch(String outputName
,
 byte[] dst) {
    fetch(outputName
,
 ByteBuffer.wrap(dst))
;

  }

  

  public void fetch(String outputName
,
 FloatBuffer dst) {
    getTensor(outputName).writeTo(dst)
;

  }

  

  public void fetch(String outputName
,
 IntBuffer dst) {
    getTensor(outputName).writeTo(dst)
;

  }

  

  public void fetch(String outputName
,
 LongBuffer dst) {
    getTensor(outputName).writeTo(dst)
;

  }

  

  public void fetch(String outputName
,
 DoubleBuffer dst) {
    getTensor(outputName).writeTo(dst)
;

  }

  

  public void fetch(String outputName
,
 ByteBuffer dst) {
    getTensor(outputName).writeTo(dst)
;

  }

  private void prepareNativeRuntime() {
    Log.i(TAG
,
 "Checking to see if TensorFlow native methods are already loaded")
;

    try {
      
      new RunStats()
;

      Log.i(TAG
,
 "TensorFlow native methods already loaded")
;

    } catch (UnsatisfiedLinkError e1) {
      Log.i(
          TAG
,
 "TensorFlow native methods not found
,
 attempting to load via tensorflow_inference")
;

      try {
        System.loadLibrary("tensorflow_inference")
;

        Log.i(TAG
,
 "Successfully loaded TensorFlow native methods (RunStats error may be ignored)")
;

      } catch (UnsatisfiedLinkError e2) {
        throw new RuntimeException(
            "Native TF methods not found
;
 check that the correct native"
                + " libraries are present in the APK.")
;

      }
    }
  }

  private void loadGraph(byte[] graphDef
,
 Graph g) throws IOException {
    final long startMs = System.currentTimeMillis()
;


    if (VERSION.SDK_INT >= 18) {
      Trace.beginSection("importGraphDef")
;

    }

    try {
      g.importGraphDef(graphDef)
;

    } catch (IllegalArgumentException e) {
      throw new IOException("Not a valid TensorFlow Graph serialization: " + e.getMessage())
;

    }

    if (VERSION.SDK_INT >= 18) {
      Trace.endSection()
;
 
    }

    final long endMs = System.currentTimeMillis()
;

    Log.i(
        TAG
,

        "Model load took " + (endMs - startMs) + "ms
,
 TensorFlow version: " + TensorFlow.version())
;

  }

  private void addFeed(String inputName
,
 Tensor<?> t) {
    
    TensorId tid = TensorId.parse(inputName)
;

    runner.feed(tid.name
,
 tid.outputIndex
,
 t)
;

    feedNames.add(inputName)
;

    feedTensors.add(t)
;

  }

  private static class TensorId {
    String name
;

    int outputIndex
;


    
    
    
,
 "foo" --> ("foo"
,
 0)
,
 while "foo:1" --> ("foo"
,
 1)
    public static TensorId parse(String name) {
      TensorId tid = new TensorId()
;

      int colonIndex = name.lastIndexOf(':')
;

      if (colonIndex < 0) {
        tid.outputIndex = 0
;

        tid.name = name
;

        return tid
;

      }
      try {
        tid.outputIndex = Integer.parseInt(name.substring(colonIndex + 1))
;

        tid.name = name.substring(0
,
 colonIndex)
;

      } catch (NumberFormatException e) {
        tid.outputIndex = 0
;

        tid.name = name
;

      }
      return tid
;

    }
  }

  private Tensor<?> getTensor(String outputName) {
    int i = 0
;

    for (String n : fetchNames) {
      if (n.equals(outputName)) {
        return fetchTensors.get(i)
;

      }
      ++i
;

    }
    throw new RuntimeException(
        "Node '" + outputName + "' was not provided to run()
,
 so it cannot be read")
;

  }

  private void closeFeeds() {
    for (Tensor<?> t : feedTensors) {
      t.close()
;

    }
    feedTensors.clear()
;

    feedNames.clear()
;

  }

  private void closeFetches() {
    for (Tensor<?> t : fetchTensors) {
      t.close()
;

    }
    fetchTensors.clear()
;

    fetchNames.clear()
;

  }

  
  private final String modelName
;

  private final Graph g
;

  private final Session sess
;


  
  private Session.Runner runner
;

  private List<String> feedNames = new ArrayList<String>()
;

  private List<Tensor<?>> feedTensors = new ArrayList<Tensor<?>>()
;

  private List<String> fetchNames = new ArrayList<String>()
;

  private List<Tensor<?>> fetchTensors = new ArrayList<Tensor<?>>()
;


  
  private RunStats runStats
;

}
